{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools as ft\n",
    "import io\n",
    "from argparse import ArgumentParser\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "from oml.const import (\n",
    "    IS_GALLERY_COLUMN,\n",
    "    IS_QUERY_COLUMN,\n",
    "    LABELS_COLUMN,\n",
    "    PATHS_COLUMN,\n",
    "    SPLIT_COLUMN,\n",
    "    X1_COLUMN,\n",
    "    X2_COLUMN,\n",
    "    Y1_COLUMN,\n",
    "    Y2_COLUMN,\n",
    ")\n",
    "from oml.utils.dataframe_format import check_retrieval_dataframe_format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_argparser() -> ArgumentParser:\n",
    "    parser = ArgumentParser()\n",
    "    parser.add_argument(\"--dataset_root\", type=Path)\n",
    "    parser.add_argument(\"--no_bboxes\", action=\"store_true\")\n",
    "    return parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cub_df(dataset_root: Path, no_bboxes: bool) -> pd.DataFrame:\n",
    "    dataset_root = Path(dataset_root)\n",
    "\n",
    "    images_txt = dataset_root / \"images.txt\"\n",
    "    train_test_split = dataset_root / \"train_test_split.txt\"\n",
    "    bounding_boxes = dataset_root / \"bounding_boxes.txt\"\n",
    "    image_class_labels = dataset_root / \"image_class_labels.txt\"\n",
    "\n",
    "    for file in [images_txt, train_test_split, bounding_boxes, image_class_labels]:\n",
    "        assert file.is_file(), f\"File {file} does not exist.\"\n",
    "\n",
    "    with open(images_txt, \"r\") as f:\n",
    "        images = f.read()\n",
    "        images = pd.read_csv(io.StringIO(images), delim_whitespace=True, header=None, names=[\"image_id\", \"image_name\"])\n",
    "\n",
    "    with open(train_test_split, \"r\") as f:\n",
    "        split = f.read()\n",
    "        split = pd.read_csv(\n",
    "            io.StringIO(split), delim_whitespace=True, header=None, names=[\"image_id\", \"is_training_image\"]\n",
    "        )\n",
    "\n",
    "    with open(bounding_boxes, \"r\") as f:\n",
    "        bbs = f.read()\n",
    "        bbs = pd.read_csv(\n",
    "            io.StringIO(bbs), delim_whitespace=True, header=None, names=[\"image_id\", \"x\", \"y\", \"width\", \"height\"]\n",
    "        )\n",
    "\n",
    "    with open(image_class_labels, \"r\") as f:\n",
    "        class_labels = f.read()\n",
    "        class_labels = pd.read_csv(\n",
    "            io.StringIO(class_labels), delim_whitespace=True, header=None, names=[\"image_id\", \"class_id\"]\n",
    "        )\n",
    "\n",
    "    df = ft.reduce(lambda left, right: pd.merge(left, right, on=\"image_id\"), [images, bbs, class_labels, split])\n",
    "\n",
    "    #print(df.head())\n",
    "\n",
    "    df[\"x_1\"] = df[\"x\"].apply(int)  # left\n",
    "    df[\"x_2\"] = (df[\"x\"] + df[\"width\"]).apply(int)  # right\n",
    "    df[\"y_2\"] = (df[\"y\"] + df[\"height\"]).apply(int)  # bot\n",
    "    df[\"y_1\"] = df[\"y\"].apply(int)  # top\n",
    "    df[\"path\"] = df[\"image_name\"].apply(lambda x: dataset_root / \"images\" / x)\n",
    "    \n",
    "\n",
    "    df[\"split\"] = \"train\"\n",
    "    #-------------------print(df[\"split\"].head())\n",
    "    df[\"split\"][df[\"is_training_image\"] == 0] = \"validation\" # -----problem here-------------\n",
    "\n",
    "    df[\"is_query\"] = None\n",
    "    df[\"is_gallery\"] = None\n",
    "    df[\"is_query\"][df[\"split\"] == \"validation\"] = True\n",
    "    df[\"is_gallery\"][df[\"split\"] == \"validation\"] = True #------propblem \n",
    "\n",
    "    df = df.rename(columns={\"class_id\": \"label\"})\n",
    "\n",
    "    cols_to_pick = [\"label\", \"path\", \"split\", \"is_query\", \"is_gallery\"]\n",
    "    if not no_bboxes:\n",
    "        cols_to_pick.extend([\"x_1\", \"x_2\", \"y_1\", \"y_2\"])\n",
    "    df = df[cols_to_pick]\n",
    "\n",
    "\n",
    "    df = df.rename(\n",
    "        columns={\n",
    "            \"label\": LABELS_COLUMN,\n",
    "            \"path\": PATHS_COLUMN,\n",
    "            \"split\": SPLIT_COLUMN,\n",
    "            \"is_query\": IS_QUERY_COLUMN,\n",
    "            \"is_gallery\": IS_GALLERY_COLUMN,\n",
    "            \"x_1\": X1_COLUMN,\n",
    "            \"x_2\": X2_COLUMN,\n",
    "            \"y_1\": Y1_COLUMN,\n",
    "            \"y_2\": Y2_COLUMN,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    if df[LABELS_COLUMN].dtype == np.int64:\n",
    "        print(\"its working\")\n",
    "    else:\n",
    "        print(\"its not working\")\n",
    "\n",
    "    t = 100\n",
    "    #print(t.dtype)\n",
    "    print()\n",
    "    \n",
    "    print(df[LABELS_COLUMN].dtype)\n",
    "\n",
    "\n",
    "    check_retrieval_dataframe_format(df, dataset_root=dataset_root)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\isehm\\AppData\\Local\\Temp\\ipykernel_28988\\2829499019.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"split\"][df[\"is_training_image\"] == 0] = \"validation\" # -----problem here-------------\n",
      "C:\\Users\\isehm\\AppData\\Local\\Temp\\ipykernel_28988\\2829499019.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"is_query\"][df[\"split\"] == \"validation\"] = True\n",
      "C:\\Users\\isehm\\AppData\\Local\\Temp\\ipykernel_28988\\2829499019.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"is_gallery\"][df[\"split\"] == \"validation\"] = True #------propblem\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "its working\n",
      "\n",
      "int64\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[39m=\u001b[39m build_cub_df(\u001b[39m\"\u001b[39;49m\u001b[39mCUB_200_2011\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m)\n",
      "Cell \u001b[1;32mIn [3], line 88\u001b[0m, in \u001b[0;36mbuild_cub_df\u001b[1;34m(dataset_root, no_bboxes)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[39mprint\u001b[39m()\n\u001b[0;32m     85\u001b[0m \u001b[39mprint\u001b[39m(df[LABELS_COLUMN]\u001b[39m.\u001b[39mdtype)\n\u001b[1;32m---> 88\u001b[0m check_retrieval_dataframe_format(df, dataset_root\u001b[39m=\u001b[39;49mdataset_root)\n\u001b[0;32m     89\u001b[0m \u001b[39mreturn\u001b[39;00m df\n",
      "File \u001b[1;32mc:\\Users\\isehm\\anaconda3\\envs\\pytroch_cpu\\lib\\site-packages\\oml\\utils\\dataframe_format.py:67\u001b[0m, in \u001b[0;36mcheck_retrieval_dataframe_format\u001b[1;34m(df, dataset_root, sep, verbose)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[39mif\u001b[39;00m dataset_root \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     65\u001b[0m     dataset_root \u001b[39m=\u001b[39m Path(\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 67\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mall\u001b[39m(df[PATHS_COLUMN]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: (dataset_root \u001b[39m/\u001b[39m x)\u001b[39m.\u001b[39mexists())\u001b[39m.\u001b[39mto_list())\n\u001b[0;32m     69\u001b[0m \u001b[39m# check bboxes if exist\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mset\u001b[39m(BBOXES_COLUMNS)\u001b[39m.\u001b[39mintersection(\u001b[39mset\u001b[39m(\u001b[39mlist\u001b[39m(df\u001b[39m.\u001b[39mcolumns))):\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df = build_cub_df(\"CUB_200_2011\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main() -> None:\n",
    "\n",
    "    input = \"python convert_cub.py --dataset_root=CUB_200_2011\"\n",
    "    \n",
    "    print(\"CUB200 2011 dataset preparation started...\")\n",
    "    #args = get_argparser().parse_args()\n",
    "    args = \"CUB_200_2011\"\n",
    "\n",
    "    print(\"------------- args=== \", args, \"-------------\")\n",
    "\n",
    "    print(\"------- this is args.dataset_root == \", args.dataset_root, \"-----------\")\n",
    "\n",
    "    df = build_cub_df(args.dataset_root, args.no_bboxes)\n",
    "\n",
    "\n",
    "    print(\"-------done-------\")\n",
    "\n",
    "\n",
    "    fname = \"df_no_bboxes\" if args.no_bboxes else \"df\"\n",
    "    df.to_csv(args.dataset_root / f\"{fname}.csv\", index=None)\n",
    "    print(\"CUB200 2011 dataset preparation completed.\")\n",
    "    print(f\"DataFrame saved in {args.dataset_root}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUB200 2011 dataset preparation started...\n",
      "------------- args===  CUB_200_2011 -------------\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'dataset_root'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m main()\n",
      "Cell \u001b[1;32mIn [10], line 11\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m args \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mCUB_200_2011\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      9\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m------------- args=== \u001b[39m\u001b[39m\"\u001b[39m, args, \u001b[39m\"\u001b[39m\u001b[39m-------------\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 11\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m------- this is args.dataset_root == \u001b[39m\u001b[39m\"\u001b[39m, args\u001b[39m.\u001b[39;49mdataset_root, \u001b[39m\"\u001b[39m\u001b[39m-----------\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     13\u001b[0m df \u001b[39m=\u001b[39m build_cub_df(args\u001b[39m.\u001b[39mdataset_root, args\u001b[39m.\u001b[39mno_bboxes)\n\u001b[0;32m     16\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m-------done-------\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'dataset_root'"
     ]
    }
   ],
   "source": [
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUB200 2011 dataset preparation started...\n",
      "------------- args===  Namespace(dataset_root=WindowsPath('CUB_200_2011'), no_bboxes=False) -------------\n",
      "------- this is args.dataset_root ==  CUB_200_2011 -----------\n",
      "its working\n",
      "int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\project\\github\\open-metric-learning\\testing_local\\cub\\convert_cub.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"split\"][df[\"is_training_image\"] == 0] = \"validation\" # -----problem here-------------\n",
      "g:\\project\\github\\open-metric-learning\\testing_local\\cub\\convert_cub.py:80: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"is_query\"][df[\"split\"] == \"validation\"] = True\n",
      "g:\\project\\github\\open-metric-learning\\testing_local\\cub\\convert_cub.py:81: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"is_gallery\"][df[\"split\"] == \"validation\"] = True #------propblem\n",
      "Traceback (most recent call last):\n",
      "  File \"g:\\project\\github\\open-metric-learning\\testing_local\\cub\\convert_cub.py\", line 140, in <module>\n",
      "    main()\n",
      "  File \"g:\\project\\github\\open-metric-learning\\testing_local\\cub\\convert_cub.py\", line 127, in main\n",
      "    df = build_cub_df(args.dataset_root, args.no_bboxes)\n",
      "  File \"g:\\project\\github\\open-metric-learning\\testing_local\\cub\\convert_cub.py\", line 116, in build_cub_df\n",
      "    check_retrieval_dataframe_format(df, dataset_root=dataset_root)\n",
      "  File \"c:\\Users\\isehm\\anaconda3\\envs\\pytroch_cpu\\lib\\site-packages\\oml\\utils\\dataframe_format.py\", line 67, in check_retrieval_dataframe_format\n",
      "    assert all(df[PATHS_COLUMN].apply(lambda x: (dataset_root / x).exists()).to_list())\n",
      "AssertionError\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "its working\n",
      "\n",
      "int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\isehm\\AppData\\Local\\Temp\\ipykernel_28988\\758327177.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"split\"][df[\"is_training_image\"] == 0] = \"validation\" # -----problem here-------------\n",
      "C:\\Users\\isehm\\AppData\\Local\\Temp\\ipykernel_28988\\758327177.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"is_query\"][df[\"split\"] == \"validation\"] = True\n",
      "C:\\Users\\isehm\\AppData\\Local\\Temp\\ipykernel_28988\\758327177.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"is_gallery\"][df[\"split\"] == \"validation\"] = True #------propblem\n"
     ]
    }
   ],
   "source": [
    "dataset_root = Path(\"CUB_200_2011\")\n",
    "no_bboxes = False\n",
    "\n",
    "images_txt = dataset_root / \"images.txt\"\n",
    "train_test_split = dataset_root / \"train_test_split.txt\"\n",
    "bounding_boxes = dataset_root / \"bounding_boxes.txt\"\n",
    "image_class_labels = dataset_root / \"image_class_labels.txt\"\n",
    "\n",
    "for file in [images_txt, train_test_split, bounding_boxes, image_class_labels]:\n",
    "    assert file.is_file(), f\"File {file} does not exist.\"\n",
    "\n",
    "with open(images_txt, \"r\") as f:\n",
    "    images = f.read()\n",
    "    images = pd.read_csv(io.StringIO(images), delim_whitespace=True, header=None, names=[\"image_id\", \"image_name\"])\n",
    "\n",
    "with open(train_test_split, \"r\") as f:\n",
    "    split = f.read()\n",
    "    split = pd.read_csv(\n",
    "        io.StringIO(split), delim_whitespace=True, header=None, names=[\"image_id\", \"is_training_image\"]\n",
    "    )\n",
    "\n",
    "with open(bounding_boxes, \"r\") as f:\n",
    "    bbs = f.read()\n",
    "    bbs = pd.read_csv(\n",
    "        io.StringIO(bbs), delim_whitespace=True, header=None, names=[\"image_id\", \"x\", \"y\", \"width\", \"height\"]\n",
    "    )\n",
    "\n",
    "with open(image_class_labels, \"r\") as f:\n",
    "    class_labels = f.read()\n",
    "    class_labels = pd.read_csv(\n",
    "        io.StringIO(class_labels), delim_whitespace=True, header=None, names=[\"image_id\", \"class_id\"]\n",
    "    )\n",
    "\n",
    "df = ft.reduce(lambda left, right: pd.merge(left, right, on=\"image_id\"), [images, bbs, class_labels, split])\n",
    "\n",
    "#print(df.head())\n",
    "\n",
    "df[\"x_1\"] = df[\"x\"].apply(int)  # left\n",
    "df[\"x_2\"] = (df[\"x\"] + df[\"width\"]).apply(int)  # right\n",
    "df[\"y_2\"] = (df[\"y\"] + df[\"height\"]).apply(int)  # bot\n",
    "df[\"y_1\"] = df[\"y\"].apply(int)  # top\n",
    "df[\"path\"] = df[\"image_name\"].apply(lambda x: dataset_root / \"images\" / x)\n",
    "\n",
    "\n",
    "df[\"split\"] = \"train\"\n",
    "#-------------------print(df[\"split\"].head())\n",
    "df[\"split\"][df[\"is_training_image\"] == 0] = \"validation\" # -----problem here-------------\n",
    "\n",
    "df[\"is_query\"] = None\n",
    "df[\"is_gallery\"] = None\n",
    "df[\"is_query\"][df[\"split\"] == \"validation\"] = True\n",
    "df[\"is_gallery\"][df[\"split\"] == \"validation\"] = True #------propblem \n",
    "\n",
    "df = df.rename(columns={\"class_id\": \"label\"})\n",
    "\n",
    "cols_to_pick = [\"label\", \"path\", \"split\", \"is_query\", \"is_gallery\"]\n",
    "if not no_bboxes:\n",
    "    cols_to_pick.extend([\"x_1\", \"x_2\", \"y_1\", \"y_2\"])\n",
    "df = df[cols_to_pick]\n",
    "\n",
    "\n",
    "df = df.rename(\n",
    "    columns={\n",
    "        \"label\": LABELS_COLUMN,\n",
    "        \"path\": PATHS_COLUMN,\n",
    "        \"split\": SPLIT_COLUMN,\n",
    "        \"is_query\": IS_QUERY_COLUMN,\n",
    "        \"is_gallery\": IS_GALLERY_COLUMN,\n",
    "        \"x_1\": X1_COLUMN,\n",
    "        \"x_2\": X2_COLUMN,\n",
    "        \"y_1\": Y1_COLUMN,\n",
    "        \"y_2\": Y2_COLUMN,\n",
    "    }\n",
    ")\n",
    "\n",
    "if df[LABELS_COLUMN].dtype == np.int64:\n",
    "    print(\"its working\")\n",
    "else:\n",
    "    print(\"its not working\")\n",
    "\n",
    "t = 100\n",
    "#print(t.dtype)\n",
    "print()\n",
    "\n",
    "print(df[LABELS_COLUMN].dtype)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('pytroch_cpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f6b1975fd18daa457b70dd04419894321ea33824326524d154cc92999765a510"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
